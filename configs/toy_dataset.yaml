estimator: # basic MLP layer configuration
  class: 'ensemble'
  model:
    num_networks : 5
    layer_sizes : [50]
  optimizer:
    class : 'Adam'
    lr : 0.01
dataset: #Â for now, just use toy-dataset
  class: 'toy'
  func: 'toy_function_complex'
  bounds: [-6, -4, 1, 4]
  sigmas: [0, 0, 0]
  imbalance_ratios: [0.1, 0.9, 0.7]
  batch_size : 128   
  test_ratio : 0.1
transforms:
  x :
    - class : standardize
  y :
    - class : standardize
train:
  train_type : iter
  num_iter : 100
# logger:
#   type: 'wandb'
#   project: 'uncertainty-estimation'
#   entity: 'kbora'
#   name: 'Toy Dataset Complex Weighted'

