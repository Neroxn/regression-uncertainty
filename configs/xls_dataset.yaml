estimator: # basic MLP layer configuration
  class: 'ensemble'
  num_networks : 5
  network:
    estimator_network:
      - fc1 : {class : Linear, in_features : 8, out_features : 50}
      - projection : {class : LinearVarianceNetworkHead, in_features : 50, out_features : 1}
    predictor_network: 
      - fc1 : {class : Linear, in_features : 8, out_features : 50}
      - projection : {class : Linear, in_features : 50, out_features : 1}
  optimizer:
    class : 'QHAdam'
    lr : 0.01
dataset:
  class: 'xls'
  xls_path: "regression_datasets/Concrete_Data.xls"
  batch_size : 512  
  cv_split_num: 10
  test_ratio: 0.10
transforms:
  x :
  - {class : Standardize , mean : [0], std : [1]}
  y :
    - {class : Standardize, mean : [0], std : [1]}
train:
  train_type : epoch
  num_iter : 40
  weight_type : both
# logger:
#   type: 'wandb'
#   project: 'uncertainty-estimation'
#   entity: 'kbora'
#   name: 'Toy Dataset Complex Weighted'